{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools as it \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide and Ideas for Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin this guide by downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X= (40, 8) , dimensions= 8\n",
      "x 1 = [0.60499445 0.17800696 0.00907698 0.50602816] ... \n",
      "x 2 = [0.29221502 0.56622265 0.81162615 0.65373012] ... \n",
      "x 3 = [0.90845275 0.99486184 0.52052036 0.36341078] ... \n",
      "x 4 = [0.35550624 0.21032501 0.07568668 0.17798105] ... \n",
      "x 5 = [0.20166872 0.32015266 0.26511183 0.0937283 ] ... \n",
      "x 6 = [0.57533801 0.70790879 0.09165169 0.19742533] ... \n",
      "x 7 = [0.31031095 0.63538449 0.59241515 0.7558269 ] ... \n",
      "x 8 = [0.73428138 0.10713163 0.36732026 0.29247234] ... \n",
      "Y= (40,) = [7.3987211  7.00522736 8.45948162 8.28400781] ...\n"
     ]
    }
   ],
   "source": [
    "def load_data(dim):\n",
    "    X = np.load('data/initial_data/function_' + str(dim) +'/initial_inputs.npy')\n",
    "    y = np.load('data/initial_data/function_' + str(dim) +'/initial_outputs.npy')\n",
    "    return X,y\n",
    "\n",
    "X, y = load_data(file)\n",
    "dimension = np.shape(X)[1] \n",
    "print(\"X=\", X.shape, \", dimensions=\", dimension)\n",
    "for i in range(dimension):\n",
    "    print(\"x\", str(i+1), \"=\", X[:,i][:4], \"... \")\n",
    "print(\"Y=\", y.shape, \"=\", y[:4], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (dimension == 2):\n",
    "    x1 =X[:,0]\n",
    "    x2 =X[:,1] \n",
    "    plt.scatter(x1, x2, c=y)\n",
    "    for (i, j, text) in zip(x1, x2, y):\n",
    "        plt.annotate(format(text, \".2e\"),  # This is the text to use for the annotation\n",
    "                 (i, j),  # This is the point to label\n",
    "                 textcoords=\"offset points\",  # how to position the text\n",
    "                 xytext=(0,10),  # distance from text to points (x,y)\n",
    "                 ha='right')  # horizontal alignment can be left, right or center\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second alternative would be to use Bayesian Optimization and consider an Upper Confidence Bound acquisition function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianProcessRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" checked><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianProcessRegressor</label><div class=\"sk-toggleable__content\"><pre>GaussianProcessRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianProcessRegressor()"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add here hyper-parameters\n",
    "gpr = GaussianProcessRegressor()\n",
    "gpr.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum X= [0.05644741 0.06595555 0.02292868 0.03878647 0.40393544 0.80105533\n",
      " 0.48830701 0.89308498] , maximum y= 9.598482002566342\n",
      "data-points= (8, 8)\n",
      "data-points[ 1 ]= [0.04515793 0.0483835  0.05160906 0.05483463 0.05806019] ... 0.06773689327873403\n",
      "data-points[ 2 ]= [0.05276444 0.05653333 0.06030222 0.06407111 0.06784   ] ... 0.07914666413125185\n",
      "data-points[ 3 ]= [0.01834294 0.01965315 0.02096336 0.02227357 0.02358378] ... 0.027514413587452945\n",
      "data-points[ 4 ]= [0.03102918 0.03324555 0.03546192 0.03767829 0.03989466] ... 0.04654376683093338\n",
      "data-points[ 5 ]= [0.32314835 0.34623038 0.3693124  0.39239443 0.41547645] ... 0.48472252862253273\n",
      "data-points[ 6 ]= [0.64084426 0.68661885 0.73239344 0.77816803 0.82394262] ... 0.9612663950666926\n",
      "data-points[ 7 ]= [0.39064561 0.41854886 0.44645212 0.47435538 0.50225864] ... 0.5859684082955923\n",
      "data-points[ 8 ]= [0.71446798 0.75525827 0.79604856 0.83683885 0.87762913] ... 0.9999999999\n"
     ]
    }
   ],
   "source": [
    "def find_maxiumum(X, y):\n",
    "    maximum_of_X = []\n",
    "    maximum_so_far = -1e99\n",
    "    for index in range(len(y)):\n",
    "        if (y[index] > maximum_so_far):\n",
    "            maximum_so_far = y[index]\n",
    "            maximum_of_X = []\n",
    "            for i in range(dimension):\n",
    "                maximum_of_X.append(X[index, i])\n",
    "    return np.array(maximum_of_X), maximum_so_far\n",
    "    \n",
    "#X_sample =np.array([[1,10], [2,20], [3,30], [4, 40]])\n",
    "#Xmax, ymax = find_maxiumum(X_sample, [3,2,5,1])\n",
    "Xmax, ymax = find_maxiumum(X, y)\n",
    "XmaxLower = Xmax - (Xmax * 0.2)\n",
    "XmaxUpper = Xmax + (Xmax * 0.2)\n",
    "print(\"maximum X=\", Xmax, \", maximum y=\", ymax)\n",
    "\n",
    "sizes = [ [2, 100],\n",
    "          [3,  80],\n",
    "          [4,  60],\n",
    "          [5,  30],\n",
    "          [6,  15],\n",
    "          [7,  10],\n",
    "          [8,  8]]\n",
    "\n",
    "#Generate each dimension \n",
    "size = sizes[dimension - 2][1]\n",
    "\n",
    "data = []\n",
    "for item in range(dimension):\n",
    "    data.append(np.linspace(max(XmaxLower[item], 0 + 1e-10), min(XmaxUpper[item], 1 - 1e-10), size))\n",
    "\n",
    "x_grid_points = np.array(data)\n",
    "\n",
    "print(\"data-points=\", x_grid_points.shape)\n",
    "for dim in range(dimension):\n",
    "    print(\"data-points[\", dim + 1, \"]=\", x_grid_points[dim][:5], \"...\", x_grid_points[dim][-1] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_grid= (16777216, 8)  =  [[0.04515793 0.05276444 0.01834294 0.03102918 0.32314835 0.64084426\n",
      "  0.39064561 0.71446798]\n",
      " [0.04515793 0.05276444 0.01834294 0.03102918 0.32314835 0.64084426\n",
      "  0.39064561 0.75525827]\n",
      " [0.04515793 0.05276444 0.01834294 0.03102918 0.32314835 0.64084426\n",
      "  0.39064561 0.79604856]\n",
      " [0.04515793 0.05276444 0.01834294 0.03102918 0.32314835 0.64084426\n",
      "  0.39064561 0.83683885]\n",
      " [0.04515793 0.05276444 0.01834294 0.03102918 0.32314835 0.64084426\n",
      "  0.39064561 0.87762913]] ... [0.06773689 0.07914666 0.02751441 0.04654377 0.48472253 0.9612664\n",
      " 0.58596841 1.        ]\n"
     ]
    }
   ],
   "source": [
    "X_grid = np.fromiter(it.chain(*it.product(*x_grid_points)), dtype=float).reshape(-1,dimension)\n",
    "print(\"X_grid=\", X_grid.shape, \" = \", X_grid[0:5,:], \"...\", X_grid[-1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_grid = np.array(X_grid)\n",
    "mean, std = gpr.predict(X_grid, return_std = True)\n",
    "ucb = mean + 1.96 * std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCB= (16777216,) , value= [10.24445569 10.16791958 10.08598454 10.00089471  9.91492033]\n",
      "mean= (16777216,) , value= [9.91103731 9.86048108 9.7997926  9.72911235 9.64860456]\n"
     ]
    }
   ],
   "source": [
    "print(\"UCB=\", ucb.shape, \", value=\", ucb[:5])\n",
    "print(\"mean=\", mean.shape, \", value=\", mean[:5])\n",
    "#print(\"mean + std(1.96)=\", mean.shape, \", value=\", (mean + std * 1.96)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06773689 0.07914666 0.02751441 0.04654377 0.4616405  0.64084426\n",
      " 0.39064561 0.71446798]\n",
      "[0.06773689327873403, 0.07914666413125185, 0.027514413587452945, 0.04654376683093338, 0.46164050345003116, 0.6408442633777951, 0.39064560553039485, 0.7144679812318023]\n"
     ]
    }
   ],
   "source": [
    "idx_max = np.argmax(ucb)\n",
    "next_query = X_grid[idx_max]\n",
    "print(next_query)\n",
    "best_numbers = []\n",
    "for item in next_query:\n",
    "    best_numbers.append(min(max(item, 0.000001), 0.999999))\n",
    "print(best_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this every week, we expect to be able to find the first of the two modes! This should would be enough to provide a good solution to the problem. To really verify if we found the maximum, we would need to find a second mode, however, we may be unlucky and simply never find it. This is an important part of Machine Learning: in theory we might want optimal, perfect solutions, but in practice most of the advancements can be done with simple solutions and careful consideration of the data available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.067737-0.079147-0.027514-0.046544-0.461641-0.640844-0.390646-0.714468]'"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array2string(np.array(best_numbers), precision=6, separator='-', floatmode='fixed', formatter={'float': '{:0.6f}'.format})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d37abda7630e259e5026a5079657683a09f6e3d11473720762ebe7250c494840"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
