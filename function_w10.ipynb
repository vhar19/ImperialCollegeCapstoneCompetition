{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, ExpSineSquared, DotProduct, ConstantKernel as C\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide and Ideas for Capstone Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin this guide by downloading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS \n",
    "# This section defines the variables to run the rest of the document \n",
    "file = 8  # Identifies the function number to execute (1,2,3...8) \n",
    "resultsFile = \"data/results10.csv\"   # The latest results file provided by Carlton on a weekly basis \n",
    "#kernel_name = \"lineal\"   # Options are default, linear and polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input= 0    [0.067737 0.079147 0.027514 0.046544 0.461641 ...\n",
      "1    [0.081284 0.094976 0.033017 0.055853 0.369313 ...\n",
      "2    [0.081284 0.094976 0.033017 0.055853 0.553969 ...\n",
      "3    [0.097541 0.113971 0.03962  0.067024 0.443175 ...\n",
      "4    [0.117049 0.136765 0.047544 0.080429 0.53181  ...\n",
      "5    [0.140459 0.109412 0.057053 0.096515 0.425448 ...\n",
      "6    [0.093639 0.164118 0.057053 0.096515 0.486226 ...\n",
      "7    [0.074911 0.131294 0.068464 0.115818 0.555687 ...\n",
      "8    [0.059929 0.105035 0.054771 0.092654 0.666824 ...\n",
      "9    [0.071915 0.084028 0.065725 0.074123 0.647772 ...\n",
      "Name: f8, dtype: object\n",
      "Output= 0    9.799602\n",
      "1    9.696555\n",
      "2    9.817107\n",
      "3    9.849910\n",
      "4    9.859542\n",
      "5    9.833724\n",
      "6    9.865061\n",
      "7    9.906853\n",
      "8    9.947503\n",
      "9    9.953320\n",
      "Name: f8_output, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>student_id</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f1_output</th>\n",
       "      <th>f2_output</th>\n",
       "      <th>f3_output</th>\n",
       "      <th>f4_output</th>\n",
       "      <th>f5_output</th>\n",
       "      <th>f6_output</th>\n",
       "      <th>f7_output</th>\n",
       "      <th>f8_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2024-05-05 12:53:51</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.877228 0.8796  ]</td>\n",
       "      <td>[0.562109 0.999999]</td>\n",
       "      <td>[0.463899 0.489275 0.408212]</td>\n",
       "      <td>[0.462212 0.386621 0.366643 0.298809]</td>\n",
       "      <td>[0.269027 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.582549 0.123754 0.586041 0.832796 0.045121]</td>\n",
       "      <td>[0.046316 0.393338 0.197938 0.174495 0.336343 ...</td>\n",
       "      <td>[0.067737 0.079147 0.027514 0.046544 0.461641 ...</td>\n",
       "      <td>2.380231e-87</td>\n",
       "      <td>0.047852</td>\n",
       "      <td>-0.005920</td>\n",
       "      <td>-1.917274</td>\n",
       "      <td>4462.544669</td>\n",
       "      <td>-0.579251</td>\n",
       "      <td>1.286160</td>\n",
       "      <td>9.799602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>2024-05-07 07:25:14</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.877228 0.758174]</td>\n",
       "      <td>[0.843164 0.999999]</td>\n",
       "      <td>[0.509702 0.39142  0.489854]</td>\n",
       "      <td>[0.426175 0.38531  0.370372 0.358571]</td>\n",
       "      <td>[0.322832 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.466039 0.148505 0.468833 0.666237 0.036097]</td>\n",
       "      <td>[0.046316 0.393338 0.197938 0.174495 0.360367 ...</td>\n",
       "      <td>[0.081284 0.094976 0.033017 0.055853 0.369313 ...</td>\n",
       "      <td>-1.758338e-55</td>\n",
       "      <td>-0.000932</td>\n",
       "      <td>-0.019979</td>\n",
       "      <td>0.563498</td>\n",
       "      <td>4484.415611</td>\n",
       "      <td>-0.763791</td>\n",
       "      <td>1.708912</td>\n",
       "      <td>9.696555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>2024-05-13 06:14:44</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.785666 0.5864  ]</td>\n",
       "      <td>[0.769352 0.892841]</td>\n",
       "      <td>[0.371119 0.39142  0.489854]</td>\n",
       "      <td>[0.34094  0.363106 0.444446 0.430285]</td>\n",
       "      <td>[0.387398 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.466039 0.148505 0.703249 0.999355 0.036097]</td>\n",
       "      <td>[0.037053 0.472006 0.15835  0.139596 0.319182 ...</td>\n",
       "      <td>[0.081284 0.094976 0.033017 0.055853 0.553969 ...</td>\n",
       "      <td>-9.346589e-20</td>\n",
       "      <td>0.266689</td>\n",
       "      <td>-0.012444</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>4528.747422</td>\n",
       "      <td>-0.569922</td>\n",
       "      <td>1.033901</td>\n",
       "      <td>9.817107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>206</td>\n",
       "      <td>2024-06-10 07:09:12</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.800434 0.811483]</td>\n",
       "      <td>[0.687022 0.999999]</td>\n",
       "      <td>[0.422794 0.313136 0.498535]</td>\n",
       "      <td>[0.34094  0.431025 0.296298 0.430285]</td>\n",
       "      <td>[0.464878 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.372831 0.118804 0.562599 0.999999 0.043316]</td>\n",
       "      <td>[0.037053 0.31467  0.237526 0.139596 0.43244  ...</td>\n",
       "      <td>[0.097541 0.113971 0.03962  0.067024 0.443175 ...</td>\n",
       "      <td>1.381414e-44</td>\n",
       "      <td>0.589400</td>\n",
       "      <td>-0.027751</td>\n",
       "      <td>-0.728106</td>\n",
       "      <td>4619.357394</td>\n",
       "      <td>-0.625573</td>\n",
       "      <td>1.401136</td>\n",
       "      <td>9.849910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265</td>\n",
       "      <td>2024-06-20 05:37:21</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.824063 0.666364]</td>\n",
       "      <td>[0.672828 0.952955]</td>\n",
       "      <td>[0.556679 0.473172 0.489854]</td>\n",
       "      <td>[0.485406 0.308248 0.444446 0.430285]</td>\n",
       "      <td>[0.557854 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.494966 0.118804 0.843899 0.806398 0.043316]</td>\n",
       "      <td>[0.037053 0.31467  0.15835  0.209394 0.288294 ...</td>\n",
       "      <td>[0.117049 0.136765 0.047544 0.080429 0.53181  ...</td>\n",
       "      <td>1.055608e-30</td>\n",
       "      <td>0.586961</td>\n",
       "      <td>-0.022115</td>\n",
       "      <td>-1.723890</td>\n",
       "      <td>4806.634380</td>\n",
       "      <td>-0.672301</td>\n",
       "      <td>2.145971</td>\n",
       "      <td>9.859542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>307</td>\n",
       "      <td>2024-06-25 06:16:12</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.700011 0.811483]</td>\n",
       "      <td>[0.740962 0.999999]</td>\n",
       "      <td>[0.668015 0.567806 0.587825]</td>\n",
       "      <td>[0.390058 0.462372 0.444446 0.352494]</td>\n",
       "      <td>[0.669425 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.634778 0.099003 0.703249 0.999355 0.054145]</td>\n",
       "      <td>[0.029642 0.251736 0.12668  0.251273 0.230635 ...</td>\n",
       "      <td>[0.140459 0.109412 0.057053 0.096515 0.425448 ...</td>\n",
       "      <td>-1.535327e-27</td>\n",
       "      <td>0.400386</td>\n",
       "      <td>-0.043506</td>\n",
       "      <td>-0.576021</td>\n",
       "      <td>5200.648778</td>\n",
       "      <td>-0.788500</td>\n",
       "      <td>2.110076</td>\n",
       "      <td>9.833724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>325</td>\n",
       "      <td>2024-06-28 04:06:03</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.762037 0.77002 ]</td>\n",
       "      <td>[0.685634 0.999999]</td>\n",
       "      <td>[0.611642 0.358719 0.471252]</td>\n",
       "      <td>[0.381391 0.365718 0.366606 0.430285]</td>\n",
       "      <td>[0.80331  0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.51425  0.148505 0.614333 0.815566 0.054145]</td>\n",
       "      <td>[0.029642 0.251736 0.12668  0.167515 0.288294 ...</td>\n",
       "      <td>[0.093639 0.164118 0.057053 0.096515 0.486226 ...</td>\n",
       "      <td>4.857872e-27</td>\n",
       "      <td>0.633161</td>\n",
       "      <td>-0.028291</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>6055.632249</td>\n",
       "      <td>-0.401099</td>\n",
       "      <td>2.025039</td>\n",
       "      <td>9.865061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>361</td>\n",
       "      <td>2024-07-01 14:33:18</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.753176 0.78779 ]</td>\n",
       "      <td>[0.699513 0.999999]</td>\n",
       "      <td>[0.611642 0.37061  0.587825]</td>\n",
       "      <td>[0.34094  0.318697 0.444446 0.303874]</td>\n",
       "      <td>[0.963972 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.4114   0.178206 0.635517 0.776194 0.064974]</td>\n",
       "      <td>[0.029642 0.350632 0.12668  0.251273 0.313005 ...</td>\n",
       "      <td>[0.074911 0.131294 0.068464 0.115818 0.555687 ...</td>\n",
       "      <td>2.058824e-29</td>\n",
       "      <td>0.557300</td>\n",
       "      <td>-0.044824</td>\n",
       "      <td>-1.277253</td>\n",
       "      <td>8013.336006</td>\n",
       "      <td>-0.292817</td>\n",
       "      <td>2.078230</td>\n",
       "      <td>9.906853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>425</td>\n",
       "      <td>2024-07-09 17:19:13</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.877228 0.5864  ]</td>\n",
       "      <td>[0.822761 0.999999]</td>\n",
       "      <td>[0.556679 0.39142  0.32657 ]</td>\n",
       "      <td>[0.34094  0.308248 0.296298 0.286857]</td>\n",
       "      <td>[0.999999 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.32912  0.142565 0.76262  0.931433 0.051979]</td>\n",
       "      <td>[0.029642 0.377604 0.12668  0.167515 0.230635 ...</td>\n",
       "      <td>[0.059929 0.105035 0.054771 0.092654 0.666824 ...</td>\n",
       "      <td>1.227291e-45</td>\n",
       "      <td>-0.083219</td>\n",
       "      <td>-0.057986</td>\n",
       "      <td>-2.760482</td>\n",
       "      <td>8662.405001</td>\n",
       "      <td>-0.621793</td>\n",
       "      <td>1.371910</td>\n",
       "      <td>9.947503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>493</td>\n",
       "      <td>2024-07-16 17:14:47</td>\n",
       "      <td>534</td>\n",
       "      <td>[0.877228 0.663402]</td>\n",
       "      <td>[0.672663 0.999999]</td>\n",
       "      <td>[0.296895 0.445922 0.54566 ]</td>\n",
       "      <td>[0.34094  0.397065 0.371627 0.362217]</td>\n",
       "      <td>[0.999999 0.999999 0.999999 0.999999]</td>\n",
       "      <td>[0.32912  0.213847 0.622368 0.760135 0.077969]</td>\n",
       "      <td>[0.029642 0.251736 0.19002  0.251273 0.27182  ...</td>\n",
       "      <td>[0.071915 0.084028 0.065725 0.074123 0.647772 ...</td>\n",
       "      <td>-4.606768e-45</td>\n",
       "      <td>0.508629</td>\n",
       "      <td>-0.039618</td>\n",
       "      <td>0.409436</td>\n",
       "      <td>8662.405001</td>\n",
       "      <td>-0.260859</td>\n",
       "      <td>2.373251</td>\n",
       "      <td>9.953320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp  student_id                   f1  \\\n",
       "0          24  2024-05-05 12:53:51         534  [0.877228 0.8796  ]   \n",
       "1          45  2024-05-07 07:25:14         534  [0.877228 0.758174]   \n",
       "2          82  2024-05-13 06:14:44         534  [0.785666 0.5864  ]   \n",
       "3         206  2024-06-10 07:09:12         534  [0.800434 0.811483]   \n",
       "4         265  2024-06-20 05:37:21         534  [0.824063 0.666364]   \n",
       "5         307  2024-06-25 06:16:12         534  [0.700011 0.811483]   \n",
       "6         325  2024-06-28 04:06:03         534  [0.762037 0.77002 ]   \n",
       "7         361  2024-07-01 14:33:18         534  [0.753176 0.78779 ]   \n",
       "8         425  2024-07-09 17:19:13         534  [0.877228 0.5864  ]   \n",
       "9         493  2024-07-16 17:14:47         534  [0.877228 0.663402]   \n",
       "\n",
       "                    f2                            f3  \\\n",
       "0  [0.562109 0.999999]  [0.463899 0.489275 0.408212]   \n",
       "1  [0.843164 0.999999]  [0.509702 0.39142  0.489854]   \n",
       "2  [0.769352 0.892841]  [0.371119 0.39142  0.489854]   \n",
       "3  [0.687022 0.999999]  [0.422794 0.313136 0.498535]   \n",
       "4  [0.672828 0.952955]  [0.556679 0.473172 0.489854]   \n",
       "5  [0.740962 0.999999]  [0.668015 0.567806 0.587825]   \n",
       "6  [0.685634 0.999999]  [0.611642 0.358719 0.471252]   \n",
       "7  [0.699513 0.999999]  [0.611642 0.37061  0.587825]   \n",
       "8  [0.822761 0.999999]  [0.556679 0.39142  0.32657 ]   \n",
       "9  [0.672663 0.999999]  [0.296895 0.445922 0.54566 ]   \n",
       "\n",
       "                                      f4  \\\n",
       "0  [0.462212 0.386621 0.366643 0.298809]   \n",
       "1  [0.426175 0.38531  0.370372 0.358571]   \n",
       "2  [0.34094  0.363106 0.444446 0.430285]   \n",
       "3  [0.34094  0.431025 0.296298 0.430285]   \n",
       "4  [0.485406 0.308248 0.444446 0.430285]   \n",
       "5  [0.390058 0.462372 0.444446 0.352494]   \n",
       "6  [0.381391 0.365718 0.366606 0.430285]   \n",
       "7  [0.34094  0.318697 0.444446 0.303874]   \n",
       "8  [0.34094  0.308248 0.296298 0.286857]   \n",
       "9  [0.34094  0.397065 0.371627 0.362217]   \n",
       "\n",
       "                                      f5  \\\n",
       "0  [0.269027 0.999999 0.999999 0.999999]   \n",
       "1  [0.322832 0.999999 0.999999 0.999999]   \n",
       "2  [0.387398 0.999999 0.999999 0.999999]   \n",
       "3  [0.464878 0.999999 0.999999 0.999999]   \n",
       "4  [0.557854 0.999999 0.999999 0.999999]   \n",
       "5  [0.669425 0.999999 0.999999 0.999999]   \n",
       "6  [0.80331  0.999999 0.999999 0.999999]   \n",
       "7  [0.963972 0.999999 0.999999 0.999999]   \n",
       "8  [0.999999 0.999999 0.999999 0.999999]   \n",
       "9  [0.999999 0.999999 0.999999 0.999999]   \n",
       "\n",
       "                                               f6  \\\n",
       "0  [0.582549 0.123754 0.586041 0.832796 0.045121]   \n",
       "1  [0.466039 0.148505 0.468833 0.666237 0.036097]   \n",
       "2  [0.466039 0.148505 0.703249 0.999355 0.036097]   \n",
       "3  [0.372831 0.118804 0.562599 0.999999 0.043316]   \n",
       "4  [0.494966 0.118804 0.843899 0.806398 0.043316]   \n",
       "5  [0.634778 0.099003 0.703249 0.999355 0.054145]   \n",
       "6  [0.51425  0.148505 0.614333 0.815566 0.054145]   \n",
       "7  [0.4114   0.178206 0.635517 0.776194 0.064974]   \n",
       "8  [0.32912  0.142565 0.76262  0.931433 0.051979]   \n",
       "9  [0.32912  0.213847 0.622368 0.760135 0.077969]   \n",
       "\n",
       "                                                  f7  \\\n",
       "0  [0.046316 0.393338 0.197938 0.174495 0.336343 ...   \n",
       "1  [0.046316 0.393338 0.197938 0.174495 0.360367 ...   \n",
       "2  [0.037053 0.472006 0.15835  0.139596 0.319182 ...   \n",
       "3  [0.037053 0.31467  0.237526 0.139596 0.43244  ...   \n",
       "4  [0.037053 0.31467  0.15835  0.209394 0.288294 ...   \n",
       "5  [0.029642 0.251736 0.12668  0.251273 0.230635 ...   \n",
       "6  [0.029642 0.251736 0.12668  0.167515 0.288294 ...   \n",
       "7  [0.029642 0.350632 0.12668  0.251273 0.313005 ...   \n",
       "8  [0.029642 0.377604 0.12668  0.167515 0.230635 ...   \n",
       "9  [0.029642 0.251736 0.19002  0.251273 0.27182  ...   \n",
       "\n",
       "                                                  f8     f1_output  f2_output  \\\n",
       "0  [0.067737 0.079147 0.027514 0.046544 0.461641 ...  2.380231e-87   0.047852   \n",
       "1  [0.081284 0.094976 0.033017 0.055853 0.369313 ... -1.758338e-55  -0.000932   \n",
       "2  [0.081284 0.094976 0.033017 0.055853 0.553969 ... -9.346589e-20   0.266689   \n",
       "3  [0.097541 0.113971 0.03962  0.067024 0.443175 ...  1.381414e-44   0.589400   \n",
       "4  [0.117049 0.136765 0.047544 0.080429 0.53181  ...  1.055608e-30   0.586961   \n",
       "5  [0.140459 0.109412 0.057053 0.096515 0.425448 ... -1.535327e-27   0.400386   \n",
       "6  [0.093639 0.164118 0.057053 0.096515 0.486226 ...  4.857872e-27   0.633161   \n",
       "7  [0.074911 0.131294 0.068464 0.115818 0.555687 ...  2.058824e-29   0.557300   \n",
       "8  [0.059929 0.105035 0.054771 0.092654 0.666824 ...  1.227291e-45  -0.083219   \n",
       "9  [0.071915 0.084028 0.065725 0.074123 0.647772 ... -4.606768e-45   0.508629   \n",
       "\n",
       "   f3_output  f4_output    f5_output  f6_output  f7_output  f8_output  \n",
       "0  -0.005920  -1.917274  4462.544669  -0.579251   1.286160   9.799602  \n",
       "1  -0.019979   0.563498  4484.415611  -0.763791   1.708912   9.696555  \n",
       "2  -0.012444   0.180900  4528.747422  -0.569922   1.033901   9.817107  \n",
       "3  -0.027751  -0.728106  4619.357394  -0.625573   1.401136   9.849910  \n",
       "4  -0.022115  -1.723890  4806.634380  -0.672301   2.145971   9.859542  \n",
       "5  -0.043506  -0.576021  5200.648778  -0.788500   2.110076   9.833724  \n",
       "6  -0.028291   0.527600  6055.632249  -0.401099   2.025039   9.865061  \n",
       "7  -0.044824  -1.277253  8013.336006  -0.292817   2.078230   9.906853  \n",
       "8  -0.057986  -2.760482  8662.405001  -0.621793   1.371910   9.947503  \n",
       "9  -0.039618   0.409436  8662.405001  -0.260859   2.373251   9.953320  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputColumnName = \"f\" + str(file)\n",
    "outputColumnName = \"f\" + str(file) + \"_output\"\n",
    "df = pd.read_csv(resultsFile)\n",
    "input = df[inputColumnName]\n",
    "output = df[outputColumnName]\n",
    "print(\"Input=\", input)\n",
    "print(\"Output=\", output)\n",
    "df.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X(shape)= (50, 8) y(shape)= (50,)\n"
     ]
    }
   ],
   "source": [
    "# LOAD INITIAL DATA PROVIDED AT THE BEGINNING \n",
    "def load_data(dim):\n",
    "    X = np.load('data/initial_data/function_' + str(dim) +'/initial_inputs.npy')\n",
    "    y = np.load('data/initial_data/function_' + str(dim) +'/initial_outputs.npy')\n",
    "    return X,y\n",
    "\n",
    "# LOAD AND APPEND THE RESULTS PUBLISHED BY CARLTON \n",
    "X, y = load_data(file)\n",
    "dimension = np.shape(X)[1] \n",
    "\n",
    "for item in input:\n",
    "     item_with_comma = \"[\" + item.replace(\" 0.\",\", 0.\")  + \"]\"  \n",
    "     row = np.array(literal_eval(item_with_comma))\n",
    "     X = np.append(X, np.array(row), axis=0)\n",
    "\n",
    "for item in output:\n",
    "    y = np.append(y, float(item))\n",
    "\n",
    "print(\"X(shape)=\", X.shape, \"y(shape)=\", y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60499445, 0.29221502, 0.90845275, 0.35550624, 0.20166872,\n",
       "        0.57533801, 0.31031095, 0.73428138],\n",
       "       [0.17800696, 0.56622265, 0.99486184, 0.21032501, 0.32015266,\n",
       "        0.70790879, 0.63538449, 0.10713163],\n",
       "       [0.00907698, 0.81162615, 0.52052036, 0.07568668, 0.26511183,\n",
       "        0.09165169, 0.59241515, 0.36732026],\n",
       "       [0.50602816, 0.65373012, 0.36341078, 0.17798105, 0.0937283 ,\n",
       "        0.19742533, 0.7558269 , 0.29247234],\n",
       "       [0.35990926, 0.24907568, 0.49599717, 0.70921498, 0.11498719,\n",
       "        0.28920692, 0.55729515, 0.59388173],\n",
       "       [0.77881834, 0.0034195 , 0.33798313, 0.51952778, 0.82090699,\n",
       "        0.53724669, 0.5513471 , 0.66003209],\n",
       "       [0.90864932, 0.0622497 , 0.23825955, 0.76660355, 0.13233596,\n",
       "        0.99024381, 0.68806782, 0.74249594],\n",
       "       [0.58637144, 0.88073573, 0.74502075, 0.54603485, 0.00964888,\n",
       "        0.74899176, 0.23090707, 0.09791562],\n",
       "       [0.76113733, 0.85467239, 0.38212433, 0.33735198, 0.68970832,\n",
       "        0.30985305, 0.63137968, 0.04195607],\n",
       "       [0.9849332 , 0.69950626, 0.9988855 , 0.18014846, 0.58014315,\n",
       "        0.23108719, 0.49082694, 0.31368272],\n",
       "       [0.11207131, 0.43773566, 0.59659878, 0.59277563, 0.22698177,\n",
       "        0.41010452, 0.92123758, 0.67475276],\n",
       "       [0.79188751, 0.57619134, 0.69452836, 0.28342378, 0.13675546,\n",
       "        0.27916186, 0.84276726, 0.62532792],\n",
       "       [0.1435503 , 0.93741452, 0.23232482, 0.00904349, 0.41457893,\n",
       "        0.40932517, 0.55377852, 0.2058408 ],\n",
       "       [0.76991655, 0.45875909, 0.55900044, 0.69460444, 0.50319902,\n",
       "        0.72834638, 0.78425353, 0.66313109],\n",
       "       [0.05644741, 0.06595555, 0.02292868, 0.03878647, 0.40393544,\n",
       "        0.80105533, 0.48830701, 0.89308498],\n",
       "       [0.86243745, 0.48273382, 0.2818694 , 0.54410223, 0.88749026,\n",
       "        0.38265469, 0.60190199, 0.47646169],\n",
       "       [0.3515119 , 0.59006494, 0.9094363 , 0.67840835, 0.21282566,\n",
       "        0.08846038, 0.410153  , 0.19572429],\n",
       "       [0.73590364, 0.03461189, 0.72803027, 0.14742652, 0.29574314,\n",
       "        0.44511731, 0.97517969, 0.37433978],\n",
       "       [0.68029397, 0.25510465, 0.86218799, 0.13439582, 0.3263292 ,\n",
       "        0.28790687, 0.43501048, 0.36420013],\n",
       "       [0.04432925, 0.01358149, 0.25819824, 0.57764416, 0.05127992,\n",
       "        0.15856307, 0.59103012, 0.07795293],\n",
       "       [0.77834548, 0.75114565, 0.31414221, 0.90298577, 0.33538166,\n",
       "        0.38632267, 0.74897249, 0.9887551 ],\n",
       "       [0.89888711, 0.5236417 , 0.87678325, 0.21869645, 0.90026089,\n",
       "        0.28276624, 0.91107791, 0.47239822],\n",
       "       [0.14512029, 0.11932754, 0.42088822, 0.38760861, 0.15542283,\n",
       "        0.87517163, 0.51055967, 0.72861058],\n",
       "       [0.33895442, 0.56693202, 0.3767511 , 0.09891573, 0.65945169,\n",
       "        0.24554809, 0.76248278, 0.73215347],\n",
       "       [0.17615002, 0.29396143, 0.97567997, 0.79393631, 0.92340076,\n",
       "        0.03084229, 0.80325452, 0.59589758],\n",
       "       [0.02894663, 0.02827906, 0.48137155, 0.6131746 , 0.67266045,\n",
       "        0.02211341, 0.6014833 , 0.52488505],\n",
       "       [0.19263987, 0.63067728, 0.41679584, 0.49052929, 0.79608602,\n",
       "        0.65456706, 0.27624119, 0.29551759],\n",
       "       [0.94318502, 0.21885062, 0.72118408, 0.42459707, 0.986902  ,\n",
       "        0.53518298, 0.71474318, 0.96009372],\n",
       "       [0.5327214 , 0.8336926 , 0.071399  , 0.11681148, 0.73069311,\n",
       "        0.93737559, 0.86650798, 0.127902  ],\n",
       "       [0.44709584, 0.84395253, 0.72954612, 0.63915138, 0.40928714,\n",
       "        0.13264569, 0.03590888, 0.44683847],\n",
       "       [0.38222497, 0.55713584, 0.85310163, 0.33379569, 0.26572127,\n",
       "        0.48087292, 0.23764706, 0.76863196],\n",
       "       [0.53281953, 0.86230848, 0.53826712, 0.04944293, 0.71970119,\n",
       "        0.9067059 , 0.10823094, 0.52534791],\n",
       "       [0.39486519, 0.33180167, 0.7407543 , 0.69786172, 0.73740444,\n",
       "        0.78377681, 0.25449546, 0.87114551],\n",
       "       [0.98594539, 0.87305363, 0.07039262, 0.05358729, 0.73415296,\n",
       "        0.52025852, 0.81104004, 0.10336036],\n",
       "       [0.96457339, 0.97397979, 0.66375335, 0.66221599, 0.67312167,\n",
       "        0.90523762, 0.45887462, 0.5609175 ],\n",
       "       [0.47207071, 0.16820264, 0.08642757, 0.45265551, 0.48061922,\n",
       "        0.62243949, 0.92897446, 0.11253627],\n",
       "       [0.85600695, 0.6388937 , 0.32619202, 0.66850311, 0.24029837,\n",
       "        0.21029889, 0.16754636, 0.96358986],\n",
       "       [0.81003174, 0.63504604, 0.26954758, 0.86960534, 0.66192159,\n",
       "        0.25225873, 0.76567003, 0.89054867],\n",
       "       [0.79625252, 0.00703653, 0.35569738, 0.48756605, 0.74051962,\n",
       "        0.7066501 , 0.99291449, 0.38173437],\n",
       "       [0.48124533, 0.10246072, 0.21948594, 0.67732237, 0.24750919,\n",
       "        0.24434086, 0.16382453, 0.71596164],\n",
       "       [0.067737  , 0.079147  , 0.027514  , 0.046544  , 0.461641  ,\n",
       "        0.640844  , 0.390646  , 0.714468  ],\n",
       "       [0.081284  , 0.094976  , 0.033017  , 0.055853  , 0.369313  ,\n",
       "        0.659154  , 0.468775  , 0.571574  ],\n",
       "       [0.081284  , 0.094976  , 0.033017  , 0.055853  , 0.553969  ,\n",
       "        0.769013  , 0.334839  , 0.775708  ],\n",
       "       [0.097541  , 0.113971  , 0.03962   , 0.067024  , 0.443175  ,\n",
       "        0.659154  , 0.306139  , 0.842197  ],\n",
       "       [0.117049  , 0.136765  , 0.047544  , 0.080429  , 0.53181   ,\n",
       "        0.640321  , 0.367367  , 0.76697   ],\n",
       "       [0.140459  , 0.109412  , 0.057053  , 0.096515  , 0.425448  ,\n",
       "        0.731795  , 0.293894  , 0.70123   ],\n",
       "       [0.093639  , 0.164118  , 0.057053  , 0.096515  , 0.486226  ,\n",
       "        0.695206  , 0.314886  , 0.745057  ],\n",
       "       [0.074911  , 0.131294  , 0.068464  , 0.115818  , 0.555687  ,\n",
       "        0.675343  , 0.269902  , 0.894068  ],\n",
       "       [0.059929  , 0.105035  , 0.054771  , 0.092654  , 0.666824  ,\n",
       "        0.540274  , 0.215922  , 0.999999  ],\n",
       "       [0.071915  , 0.084028  , 0.065725  , 0.074123  , 0.647772  ,\n",
       "        0.463092  , 0.172738  , 0.885714  ]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.3987211 , 7.00522736, 8.45948162, 8.28400781, 8.60611679,\n",
       "       8.54174792, 7.32743458, 7.29987205, 7.95787474, 5.59219339,\n",
       "       7.85454099, 6.79198578, 8.97655402, 7.3790829 , 9.598482  ,\n",
       "       8.15998319, 7.13162397, 6.76796253, 7.43374407, 9.01307515,\n",
       "       7.31089382, 5.84106731, 9.14163949, 8.81755844, 6.45194313,\n",
       "       8.83074505, 9.34427428, 6.88784639, 8.04221254, 7.69236805,\n",
       "       7.92375877, 8.42175924, 8.2780624 , 7.11345716, 6.40258841,\n",
       "       8.47293632, 7.97768459, 7.46087219, 7.43659353, 9.18300525,\n",
       "       9.79960224, 9.69655457, 9.81710696, 9.84991022, 9.85954215,\n",
       "       9.83372387, 9.86506113, 9.90685296, 9.94750315, 9.95332045])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first 2 functions can be shown as X,Y coordinates and reveal what is going on. On higher dimensions it loses meaning so we don't plot it \n",
    "if (dimension == 1 or dimension == 2):\n",
    "    x1 =X[:,0]\n",
    "    x2 =X[:,1] \n",
    "    plt.scatter(x1, x2, c=y)\n",
    "    for (i, j, text) in zip(x1, x2, y):\n",
    "        plt.annotate(format(text, \".2e\"),  # This is the text to use for the annotation\n",
    "                 (i, j),  # This is the point to label\n",
    "                 textcoords=\"offset points\",  # how to position the text\n",
    "                 xytext=(0,10),  # distance from text to points (x,y)\n",
    "                 ha='right')  # horizontal alignment can be left, right or center\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upper Confidence Bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second alternative would be to use Bayesian Optimization and consider an Upper Confidence Bound acquisition function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "c:\\Users\\vhar1\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:659: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters found:  OrderedDict([('estimator', GaussianProcessRegressor(alpha=0.0021188154764215273,\n",
      "                         kernel=1**2 * ExpSineSquared(length_scale=1, periodicity=1),\n",
      "                         n_restarts_optimizer=7)), ('estimator__alpha', 0.0021188154764215273), ('estimator__n_restarts_optimizer', 7)])\n",
      "Best score:  0.9587754035245798\n",
      "Pipeline(steps=[('estimator',\n",
      "                 GaussianProcessRegressor(alpha=0.0021188154764215273,\n",
      "                                          kernel=1**2 * ExpSineSquared(length_scale=1, periodicity=1),\n",
      "                                          n_restarts_optimizer=7))])\n"
     ]
    }
   ],
   "source": [
    "# CHANGED FROM MANUAL TO BAYES OPTIMIZATION \n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical\n",
    "\n",
    "\n",
    "estimator_list = [GaussianProcessRegressor(kernel=C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\")),\n",
    "                  GaussianProcessRegressor(kernel=C(1.0, constant_value_bounds=\"fixed\") * Matern(length_scale=1.0, nu=1.5)),\n",
    "                  GaussianProcessRegressor(kernel=C(1.0, constant_value_bounds=\"fixed\") * RationalQuadratic(length_scale=1.0, alpha=1.5)),\n",
    "                  GaussianProcessRegressor(kernel=C(1.0, constant_value_bounds=\"fixed\") * ExpSineSquared(length_scale=1, periodicity=1)),\n",
    "                  GaussianProcessRegressor(kernel=C(1.0, constant_value_bounds=\"fixed\") * DotProduct(sigma_0=1.0))]\n",
    "\n",
    "pipe=Pipeline([('estimator',GaussianProcessRegressor())])\n",
    "\n",
    "param = {\n",
    "    'estimator': Categorical(estimator_list),\n",
    "    'estimator__n_restarts_optimizer': (5,10),\n",
    "    'estimator__alpha': (1e-5, 1e-2,'log-uniform')\n",
    "}\n",
    "\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=pipe,\n",
    "    search_spaces=param,\n",
    "    cv=3,\n",
    "    scoring=\"r2\",\n",
    "    random_state=42,\n",
    "    n_iter=25,\n",
    "    verbose=1,\n",
    ")  \n",
    "\n",
    "bayes_search.fit(X, y)\n",
    "\n",
    "#kernels = [\n",
    "#    C(1.0, constant_value_bounds=\"fixed\") * RBF(1.0, length_scale_bounds=\"fixed\"),\n",
    "#    C(1.0, (1e-2, 1e2)) * Matern(length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=1.5),\n",
    "#    C(1.0, (1e-2, 1e2)) * RationalQuadratic(length_scale=1.0, alpha=0.1, alpha_bounds=(1e-2, 1e2)),\n",
    "#    C(1.0, (1e-2, 1e2)) * ExpSineSquared(length_scale=1.0, periodicity=3.0, periodicity_bounds=(1e-2, 1e1)),\n",
    "#    C(1.0, constant_value_bounds=\"fixed\") * DotProduct(sigma_0=1.0)\n",
    "#]\n",
    "#\n",
    "## Define the search space for a single kernel type (RBF in this example)\n",
    "#search_space = {\n",
    "#    'kernel__k1__constant_value': Real(1e-2, 1e2, prior='log-uniform'),\n",
    "#    'kernel__k2__length_scale': Real(1e-2, 1e2, prior='log-uniform')\n",
    "#}\n",
    "#\n",
    "## Create the Gaussian Process Regressor with an initial kernel (RBF in this example)\n",
    "#gpr = GaussianProcessRegressor(kernel=kernels[0])\n",
    "#\n",
    "## Create a Bayesian optimization search object\n",
    "#bayes_search = BayesSearchCV(estimator=gpr, search_spaces=search_space, n_iter=32, cv=5, scoring='neg_mean_squared_error', random_state=0)\n",
    "#\n",
    "## Fit the Bayesian search to the data\n",
    "#bayes_search.fit(X, y)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", bayes_search.best_params_)\n",
    "print(\"Best score: \", bayes_search.best_score_)\n",
    "\n",
    "# Update the GPR with the best kernel\n",
    "gpr = bayes_search.best_estimator_\n",
    "\n",
    "\n",
    "print(gpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum X= [0.071915 0.084028 0.065725 0.074123 0.647772 0.463092 0.172738 0.885714] , maximum y= 9.9533204500384\n",
      "data-points= (8, 8)\n",
      "data-points[ 1 ]= [0.057532   0.06164143 0.06575086 0.06986029 0.07396971] ... 0.08629800000000001\n",
      "data-points[ 2 ]= [0.0672224 0.072024  0.0768256 0.0816272 0.0864288] ... 0.10083360000000001\n",
      "data-points[ 3 ]= [0.05258    0.05633571 0.06009143 0.06384714 0.06760286] ... 0.07887000000000001\n",
      "data-points[ 4 ]= [0.0592984 0.063534  0.0677696 0.0720052 0.0762408] ... 0.08894759999999999\n",
      "data-points[ 5 ]= [0.5182176  0.55523314 0.59224869 0.62926423 0.66627977] ... 0.7773264\n",
      "data-points[ 6 ]= [0.3704736 0.396936  0.4233984 0.4498608 0.4763232] ... 0.5557104\n",
      "data-points[ 7 ]= [0.1381904  0.14806114 0.15793189 0.16780263 0.17767337] ... 0.20728560000000001\n",
      "data-points[ 8 ]= [0.7085712  0.75020389 0.79183657 0.83346926 0.87510194] ... 0.9999999999\n"
     ]
    }
   ],
   "source": [
    "def find_maxiumum(X, y):\n",
    "    maximum_of_X = []\n",
    "    maximum_so_far = -1e99\n",
    "    for index in range(len(y)):\n",
    "        if (y[index] > maximum_so_far):\n",
    "            maximum_so_far = y[index]\n",
    "            maximum_of_X = []\n",
    "            for i in range(dimension):\n",
    "                maximum_of_X.append(X[index, i])\n",
    "    return np.array(maximum_of_X), maximum_so_far\n",
    "    \n",
    "discovery_radius = 0.2   # on each datapoint use 20% discovery radius\n",
    "\n",
    "Xmax, ymax = find_maxiumum(X, y)  #Returns the row with maximim y and all X values \n",
    "XmaxLower = Xmax - (Xmax * discovery_radius)\n",
    "XmaxUpper = Xmax + (Xmax * discovery_radius)\n",
    "print(\"maximum X=\", Xmax, \", maximum y=\", ymax)\n",
    "\n",
    "# Adjust sizes as we go up in dimensions to avoid waiting for hours on higher dimensions \n",
    "# ********* For the purpose of unblocking any memory issue please decrease these values to adjust to your computer specs ******************\n",
    "sizes = [ [2, 100],\n",
    "          [3,  80],\n",
    "          [4,  60],\n",
    "          [5,  30],\n",
    "          [6,  15],\n",
    "          [7,  10],\n",
    "          [8,  8]]\n",
    "\n",
    "size = sizes[dimension - 2][1]  #Find the corrects size for this dimension \n",
    "\n",
    "data = []\n",
    "for item in range(dimension):\n",
    "    #  Upper lower min and max explanation: \n",
    "    #  This iteration (each X value) creates a number of points of size \"size\" in a radius of +/-20% and ensures this radius is between 0 and 1, e.g.  \n",
    "    # - X values [0.5, 0, 0.99] \n",
    "    # - apply 20% discovery radius => [(0.4 to 0.6), (0 to 0), (0.792 to 1.188)] \n",
    "    # - apply 0 to 1 filter => [ linspace(0.4 to 0.6), linspace(0 to 0.0001), linspace(9.792 to 9.9999)]\n",
    "    # - result = [ [0.48777254 ... 0.59072617], [0.000002, ... 0.000099], [9.7921111, ...9.998888] ]\n",
    "    if (XmaxUpper[item] == 0):\n",
    "        XmaxUpper[item] = 0.0001\n",
    "    if (XmaxLower[item] == 1):\n",
    "        XmaxLower[item] = 0.9999\n",
    "    data.append(np.linspace(max(XmaxLower[item], 0 + 1e-10), min(XmaxUpper[item], 1 - 1e-10), size))\n",
    "\n",
    "x_grid_points = np.array(data)\n",
    "\n",
    "print(\"data-points=\", x_grid_points.shape)\n",
    "for dim in range(dimension):\n",
    "    print(\"data-points[\", dim + 1, \"]=\", x_grid_points[dim][:5], \"...\", x_grid_points[dim][-1] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_grid= (16777216, 8)  =  [[0.057532   0.0672224  0.05258    0.0592984  0.5182176  0.3704736\n",
      "  0.1381904  0.7085712 ]\n",
      " [0.057532   0.0672224  0.05258    0.0592984  0.5182176  0.3704736\n",
      "  0.1381904  0.75020389]\n",
      " [0.057532   0.0672224  0.05258    0.0592984  0.5182176  0.3704736\n",
      "  0.1381904  0.79183657]\n",
      " [0.057532   0.0672224  0.05258    0.0592984  0.5182176  0.3704736\n",
      "  0.1381904  0.83346926]\n",
      " [0.057532   0.0672224  0.05258    0.0592984  0.5182176  0.3704736\n",
      "  0.1381904  0.87510194]] ... [0.086298  0.1008336 0.07887   0.0889476 0.7773264 0.5557104 0.2072856\n",
      " 1.       ]\n"
     ]
    }
   ],
   "source": [
    "# Apply grid search = cartesian product of the array, e.g. data of shape (2,100) => (100 x 100) = (10000, 2)\n",
    "X_grid = np.fromiter(it.chain(*it.product(*x_grid_points)), dtype=float).reshape(-1,dimension)\n",
    "print(\"X_grid=\", X_grid.shape, \" = \", X_grid[0:5,:], \"...\", X_grid[-1,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced\n",
      "UCB= (16777216,) , value= [10.0013482   9.99328852  9.98320213  9.97126749  9.95762638]\n",
      "mean= (16777216,) , value= [9.88518573 9.88166502 9.87440602 9.86338876 9.84859469]\n",
      "[0.08629800000000001, 0.10083360000000001, 0.07887000000000001, 0.08894759999999999, 0.7032953142857143, 0.44986080000000006, 0.20728560000000001, 0.7085712]\n",
      "\n",
      "\n",
      "exploitative\n",
      "UCB= (16777216,) , value= [9.9444523  9.93861578 9.92991424 9.91842893 9.90422311]\n",
      "mean= (16777216,) , value= [9.88518573 9.88166502 9.87440602 9.86338876 9.84859469]\n",
      "[0.08629800000000001, 0.10083360000000001, 0.07887000000000001, 0.08894759999999999, 0.6662797714285714, 0.44986080000000006, 0.20728560000000001, 0.7085712]\n",
      "\n",
      "\n",
      "exploratory\n",
      "UCB= (16777216,) , value= [10.03335214 10.02404193 10.01317657 10.00098918  9.98766573]\n",
      "mean= (16777216,) , value= [9.88518573 9.88166502 9.87440602 9.86338876 9.84859469]\n",
      "[0.08629800000000001, 0.10083360000000001, 0.07887000000000001, 0.08894759999999999, 0.7773264, 0.44986080000000006, 0.20728560000000001, 0.7085712]\n"
     ]
    }
   ],
   "source": [
    "mean, std = gpr.predict(X_grid, return_std = True)\n",
    "\n",
    "def calculate_ucb(beta):   \n",
    "    ucb = mean + beta * std\n",
    "    print(\"UCB=\", ucb.shape, \", value=\", ucb[:5])\n",
    "    print(\"mean=\", mean.shape, \", value=\", mean[:5])\n",
    "    idx_max = np.argmax(ucb)   # take the index of the highest confidence result \n",
    "    next_query = X_grid[idx_max]    # next_query is the point with highest confidence in this grid of search \n",
    "    best_numbers = []\n",
    "    for item in next_query:\n",
    "        best_numbers.append(min(max(item, 0.000001), 0.999999))   # ensure the numbers are between 0 and 1 \n",
    "    print(best_numbers)\n",
    "    return best_numbers\n",
    "\n",
    "def print_results(label, best_numbers):\n",
    "    #Formats the values in a way it can be copied and pasted into the weekly submission form \n",
    "    print(label)\n",
    "    print(np.array2string(np.array(best_numbers), precision=6, separator='-', floatmode='fixed', formatter={'float': '{:0.6f}'.format}))\n",
    "\n",
    "print(\"balanced\")\n",
    "balanced = calculate_ucb(1.96)  #keep it balanced\n",
    "\n",
    "print(\"\\n\\nexploitative\")\n",
    "exploitative = calculate_ucb(1.0)   #lets exploit target area\n",
    "\n",
    "print(\"\\n\\nexploratory\")\n",
    "exploratory = calculate_ucb(2.5)   #lets explore more \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('estimator', GaussianProcessRegressor(alpha=0.0021188154764215273,\n",
      "                         kernel=1**2 * ExpSineSquared(length_scale=1, periodicity=1),\n",
      "                         n_restarts_optimizer=7)), ('estimator__alpha', 0.0021188154764215273), ('estimator__n_restarts_optimizer', 7)])\n",
      "exploitative\n",
      "[0.086298-0.100834-0.078870-0.088948-0.666280-0.449861-0.207286-0.708571]\n",
      "\n",
      "balanced\n",
      "[0.086298-0.100834-0.078870-0.088948-0.703295-0.449861-0.207286-0.708571]\n",
      "\n",
      "exploratory\n",
      "[0.086298-0.100834-0.078870-0.088948-0.777326-0.449861-0.207286-0.708571]\n"
     ]
    }
   ],
   "source": [
    "print(bayes_search.best_params_)\n",
    "\n",
    "print_results(\"exploitative\", exploitative)\n",
    "\n",
    "print_results(\"\\nbalanced\", balanced)\n",
    "\n",
    "print_results(\"\\nexploratory\", exploratory)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d37abda7630e259e5026a5079657683a09f6e3d11473720762ebe7250c494840"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
